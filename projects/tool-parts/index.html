<!DOCTYPE HTML>
<!--
    Dopetrope by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    <head>
        <title>Laboratory for Progress</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    </head>
    <body class="homepage is-preload">
        <div id="page-wrapper">

            <section id="header-project">
                <h1><a href="https://progress.eecs.umich.edu/">Laboratory for Progress</a></h1>
                <p>Perceptive Robotics and Grounded Reasoning Systems</a></p>
            </section>

            <section id="main">
                <div class="container">

                    <!-- Content -->
                    <article class="box post project">
                        <header>
                            <h2>Parts-Based Articulated Object Localization in Clutter using Belief Propagation</h2>
                            <p>Jana Pavlasek, Stanley Lewis, Karthik Desingh, Odest Chadwicke Jenkins</p>
                        </header>

                        <!-- Path to a pitch image. -->
                        <div class="image pitch centered"><img src="images/pitch_figure.png" alt="" /></div>

                        <p>
                            Robots working in human environments must be able to perceive and act on challenging objects with articulations, such as a pile of tools. Articulated objects increase the dimensionality of the pose estimation problem, and partial observations under clutter create additional challenges. To address this problem, we present a generative-discriminative parts-based recognition and localization framework for articulated objects in clutter. We formulate the problem of articulated object pose estimation as a Markov Random Field (MRF). Hidden nodes in this MRF express the pose of the parts, and edges express the articulation constraints between parts. Localization is performed within the MRF using an efficient belief propagation method. The method is informed by both part segmentation heatmaps over the observation, provided by a neural network, and the articulation constraints between object parts. Our generative-discriminative approach allows the proposed method to function in cluttered environments by inferring the pose of occluded parts using hypotheses from the visible parts. We demonstrate the efficacy of our methods in a tabletop environment for recognizing and localizing hand tools in uncluttered and cluttered configurations.
                        </p>

                        <!-- Link to PDF. -->
                        <p><a href="https://arxiv.org/abs/2008.02881"><i class="fa fa-file-pdf"></i> Read the Paper</a></p>


                    </article>

                    <article class="box post">
                        <header>
                            <h2>Video</h2>
                        </header>

                        <!-- Link to video on YouTube. -->
                        <div class="video-container">
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/qwIuUwkwykI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                        </div>
                    </article>

                    <article class="box post">
                        <header>
                            <h2>Citation</h2>
                        </header>

                        <div class="citation">

<pre><code>@inproceedings{pavlasek2020parts,
  author = {Pavlasek, Jana and Lewis, Stanley and Desingh, Karthik and Jenkins, Odest Chadwicke},
  title = {Parts-Based Articulated Object Localization in Clutter Using Belief Propagation},
  booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
  year = {2020},
  organization={IEEE}
}</code></pre>
                        </div>
                    </article>




                </div>
            </section>

            <section id="footer">

                <!-- Copyright -->
                <div id="copyright">
                    <ul class="links">
                        <li>&copy; 2020. All rights reserved.</li><li>Design: Dopetrope by
                    <a href="http://twitter.com/ajlkn">AJ</a> for <a href="http://html5up.net/">HTML5 UP</li>
                    </ul>
                </div>

            </section>

        </div>

        <!-- Scripts -->
            <script src="assets/js/jquery.min.js"></script>
            <script src="assets/js/jquery.dropotron.min.js"></script>
            <script src="assets/js/browser.min.js"></script>
            <script src="assets/js/breakpoints.min.js"></script>
            <script src="assets/js/util.js"></script>
            <script src="assets/js/main.js"></script>

    </body>
</html>
